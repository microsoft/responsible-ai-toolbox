{
  "Core": {
    "ExpandableText": {
      "SeeMore": "Mehr anzeigen",
      "SeeLess": "Weniger anzeigen"
    }
  },
  "Interpret": {
    "calloutTitle": "Hier klicken, um Informationen zu erhalten",
    "selectPoint": "Markieren Sie einen Punkt, um seine lokale Erläuterung zu sehen",
    "defaultClassNames": "Klasse {0}",
    "defaultFeatureNames": "Attribut {0}",
    "absoluteAverage": "Mittelwert des absoluten Werts",
    "predictedClass": "Vorhergesagte Klasse",
    "datasetExplorer": "Dataset-Explorer",
    "dataExploration": "Datasetuntersuchung",
    "aggregateFeatureImportance": "Aggregierte Attributrelevanz",
    "globalImportance": "Globale Relevanz",
    "explanationExploration": "Durchsuchen der Erklärung",
    "individualImportance": "Individuelle Attributrelevanz",
    "individualAndWhatIf": "Individuelle Attributrelevanz und Was-wäre-wenn-Analyse",
    "summaryImportance": "Zusammenfassung – Relevanz",
    "featureImportance": "Attributrelevanz",
    "featureImportanceOf": "Featurerelevanz von {0}",
    "perturbationExploration": "Durchsuchen des Störeinflusses",
    "localFeatureImportance": "Lokale Featurerelevanz",
    "ice": "ICE",
    "clearSelection": "Auswahl löschen",
    "feature": "Attribut:",
    "intercept": "Abfangen",
    "modelPerformance": "Leistung des Modells",
    "ExplanationScatter": {
      "dataLabel": "Daten : {0}",
      "importanceLabel": "Relevanz : {0}",
      "predictedY": "Vorhersage für Y",
      "index": "Index",
      "dataGroupLabel": "Daten",
      "output": "Ausgabe",
      "probabilityLabel": "Wahrscheinlichkeit : {0}",
      "trueY": "TRUE Y",
      "class": "Klasse: ",
      "xValue": "X-Wert:",
      "yValue": "Y-Wert:",
      "colorValue": "Farbe:",
      "count": "Anzahl"
    },
    "CrossClass": {
      "label": "Klassenübergreifende Gewichtung:",
      "info": "Informationen zur klassenübergreifenden Berechnung",
      "overviewInfo": "Multiklassenmodelle generieren für jede Klasse einen unabhängigen Attributrelevanzvektor. Der Attributrelevanzvektor der einzelnen Klassen zeigt, welche Features eine Klasse wahrscheinlicher oder unwahrscheinlicher werden ließen. Sie können auswählen, wie die Gewichtungen der Attributrelevanzvektoren pro Klasse zu einem einzigen Wert zusammengefasst werden:",
      "absoluteValInfo": "Durchschnitt des absoluten Werts: Zeigt die Summe der Relevanz des Attributs für alle möglichen Klassen, geteilt durch die Klassenanzahl.",
      "predictedClassInfo": "Vorhergesagte Klasse: Zeigt den Wert der Attributrelevanz für die vorhergesagte Klasse eines bestimmten Punkts an.",
      "enumeratedClassInfo": "Aufgelistete Klassennamen: Zeigt nur die Attributrelevanz der angegebenen Klasse für alle Datenpunkte an.",
      "close": "Schließen",
      "crossClassWeights": "Klassenübergreifende Gewichtungen"
    },
    "AggregateImportance": {
      "scaledFeatureValue": "Attributwert auf Farbskala",
      "low": "Niedrig",
      "high": "Hoch",
      "featureLabel": "Attribut: {0}",
      "valueLabel": "Attributwert: {0}",
      "importanceLabel": "Relevanz: {0}",
      "predictedClassTooltip": "Vorhergesagte Klasse: {0}",
      "trueClassTooltip": "TRUE-Klasse: {0}",
      "predictedOutputTooltip": "Vorhergesagte Ausgabe: {0}",
      "trueOutputTooltip": "TRUE-Ausgabe: {0}",
      "topKFeatures": "Wichtigste K-Attribute:",
      "topKInfo": "Gibt an, wie die Top-K-Berechnung erfolgt.",
      "predictedValue": "Vorhergesagter Wert",
      "predictedClass": "Vorhergesagte Klasse",
      "trueValue": "TRUE-Wert",
      "trueClass": "TRUE-Klasse",
      "noColor": "Keine",
      "tooManyRows": "Das angegebene Dataset ist größer als von diesem Diagramm unterstützt wird"
    },
    "BarChart": {
      "classLabel": "Klasse: {0}",
      "sortBy": "Sortieren nach",
      "noData": "Keine Daten",
      "absoluteGlobal": "Absolut global",
      "absoluteLocal": "Absolut lokal",
      "calculatingExplanation": "Erklärung wird berechnet"
    },
    "IcePlot": {
      "numericError": "Muss numerisch sein.",
      "integerError": "Muss eine ganze Zahl sein.",
      "prediction": "Vorhersage",
      "predictedProbability": "Wahrscheinlichkeitsvorhersage",
      "predictionLabel": "Vorhersage: {0}",
      "probabilityLabel": "Wahrscheinlichkeit: {0}",
      "noModelError": "Geben Sie ein operationalisiertes Modell an, um Vorhersagen in ICE-Plots zu untersuchen.",
      "featurePickerLabel": "Attribut:",
      "minimumInputLabel": "Minimum:",
      "maximumInputLabel": "Maximum:",
      "stepInputLabel": "Schritte:",
      "loadingMessage": "Daten werden geladen …",
      "submitPrompt": "Übermitteln Sie einen Bereich, um einen ICE-Plot anzuzeigen.",
      "topLevelErrorMessage": "Fehler in Parameter",
      "errorPrefix": "Fehler erkannt: {0}"
    },
    "PerturbationExploration": {
      "loadingMessage": "Wird geladen...",
      "perturbationLabel": "Störeinfluss:"
    },
    "PredictionLabel": {
      "predictedValueLabel": "Vorhergesagter Wert: {0}",
      "predictedClassLabel": "Vorhergesagte Klasse : {0}"
    },
    "Violin": {
      "groupNone": "Keine Gruppierung",
      "groupPredicted": "Vorhersage für Y",
      "groupTrue": "TRUE Y",
      "groupBy": "Gruppieren nach"
    },
    "FeatureImportanceWrapper": {
      "chartType": "Diagrammtyp:",
      "violinText": "Violine",
      "barText": "Leiste",
      "boxText": "Feld",
      "beehiveText": "Swarm",
      "globalImportanceExplanation": "Die globale Attributrelevanz wird berechnet, indem der Durchschnitt des absoluten Werts der Attributrelevanz aller Punkte ermittelt wird (L1-Normalisierung). ",
      "multiclassImportanceAddendum": "Bei der Berechnung der Attributrelevanz für alle Klassen werden alle Punkte berücksichtigt, es wird keine differenzielle Gewichtung verwendet. Ein Feature mit hoher negativer Relevanz, bei dem viele Punkte in der Vorhersage nicht der \"Klasse A\" zugeordnet werden, führt daher zu einer erheblich erhöhten Attributrelevanz der \"Klasse A\"."
    },
    "Filters": {
      "equalComparison": "Gleich",
      "greaterThanComparison": "Ist größer als",
      "greaterThanEqualToComparison": "Größer als oder gleich",
      "lessThanComparison": "Weniger als",
      "lessThanEqualToComparison": "Kleiner als oder gleich",
      "inTheRangeOf": "Im Bereich von",
      "categoricalIncludeValues": "Eingeschlossene Werte:",
      "numericValue": "Wert",
      "numericalComparison": "Vorgang",
      "minimum": "Minimum",
      "maximum": "Maximum",
      "min": "Min.: {0}",
      "max": "Max.: {0}",
      "uniqueValues": "# eindeutiger Werte: {0}"
    },
    "Columns": {
      "regressionError": "Regressionsfehler",
      "error": "Fehler",
      "classificationOutcome": "Klassifizierungsergebnis",
      "truePositive": "Richtig positives Ergebnis",
      "trueNegative": "Richtig negatives Ergebnis",
      "falsePositive": "Falsch positives Ergebnis",
      "falseNegative": "Falsch negativ",
      "dataset": "Dataset",
      "predictedProbabilities": "Vorhersagewahrscheinlichkeiten",
      "none": "Anzahl"
    },
    "WhatIf": {
      "closeAriaLabel": "Schließen",
      "defaultCustomRootName": "Kopie von Zeile {0}",
      "filterFeaturePlaceholder": "Attribute durchsuchen"
    },
    "Cohort": {
      "cohort": "Kohorte",
      "defaultLabel": "Alle Daten"
    },
    "GlobalTab": {
      "collapsedHelperText": "Erkunden Sie die 1000 wichtigsten relevanten Attribute, die sich auf Ihre Gesamtmodellvorhersagen auswirken.",
      "helperText": "Verwenden Sie den Schieberegler, um die Relevanz von absteigenden Attribute zu zeigen. Wählen Sie bis zu drei Kollegen aus, um deren Attributrelevanz nebeneinander zu sehen. Klicken Sie auf eines der Attribute im Diagramm, um eine Dichtediagramm unterhalb der Werte des ausgewählten Attribute auf die Vorhersage zu sehen.",
      "topAtoB": "Wichtigste {0}-{1} Attribute",
      "datasetCohorts": "Dataset-Kohorten",
      "legendHelpText": "Aktivieren und deaktivieren Sie die Kohorten im Plot, indem Sie auf die Legendenelemente klicken.",
      "sortBy": "Sortieren nach",
      "viewDependencePlotFor": "Abhängigkeitsplot anzeigen für:",
      "datasetCohortSelector": "Dataset-Kohorte auswählen",
      "aggregateFeatureImportance": "Aggregierte Attributrelevanz",
      "missingParameters": "Auf dieser Registerkarte muss der Parameter für die lokale Attributrelevanz angegeben werden.",
      "weightOptions": "Gewichtungen der Klassenrelevanz",
      "dependencePlotTitle": "Abhängigkeitsplots",
      "dependencePlotHelperText": "Dieser Abhängigkeitsplot zeigt die Beziehung zwischen dem Wert eines Attributs und der entsprechenden Attributrelevanz in einer Kohorte.",
      "dependencePlotFeatureSelectPlaceholder": "Attribut auswählen",
      "datasetRequired": "Für Abhängigkeitsplots sind das Auswertungsdataset und das Array lokaler Attributrelevanz erforderlich."
    },
    "CohortBanner": {
      "details": "Details",
      "name": "Name",
      "dataStatistics": "Datenstatistik",
      "datapoints": "{0} Datenpunkte",
      "features": "{0} Attribute",
      "filters": "{0} Filter",
      "binaryClassifier": "Binären Klassifizierung",
      "regressor": "Regressor",
      "multiclassClassifier": "Klassifizierung für mehrere Klassen",
      "datasetCohorts": "Dataset-Kohorten",
      "editCohort": "Kohorte bearbeiten",
      "duplicateCohort": "Doppelt vorhanden",
      "addCohort": "Neue Kohorte",
      "copy": " Kopie"
    },
    "ModelPerformance": {
      "collapsedHelperText": "Werten Sie die Leistung Ihres Modells aus, indem Sie die Verteilung Ihrer Vorhersagewerte und die Werte Ihrer Modellleistungsmetriken untersuchen.",
      "helperText": "Sie können Ihr Modell näher untersuchen, indem Sie sich eine vergleichende Analyse seiner Leistung in verschiedenen Kohorten oder Untergruppen Ihres Datasets ansehen. Wählen Sie Filter entlang des Y-Werts und des X-Werts aus, um unterschiedliche Dimensionen einzubeziehen. Wählen Sie das Zahnrad im Diagramm aus, um den Diagrammtyp zu ändern.",
      "modelStatistics": "Modellstatistiken",
      "cohortPickerLabel": "Wählen Sie eine Dataset-Kohorte zur Untersuchung aus",
      "missingParameters": "Auf dieser Registerkarte muss das Array der vorhergesagten Werte aus dem Modell angegeben werden.",
      "missingTrueY": "Für die Modellleistungsstatistik müssen zusätzlich zu den vorhergesagten Ergebnissen die tatsächlichen Ergebnisse angegeben werden."
    },
    "Charts": {
      "yValue": "Y-Wert",
      "numberOfDatapoints": "Anzahl von Datenpunkten",
      "xValue": "X-Wert",
      "rowIndex": "Zeilenindex",
      "featureImportance": "Attributrelevanz",
      "countTooltipPrefix": "Anzahl: {0}",
      "count": "Anzahl",
      "featurePrefix": "Attribut",
      "importancePrefix": "Relevanz",
      "cohort": "Kohorte",
      "howToRead": "Lesen dieses Diagramms"
    },
    "DatasetExplorer": {
      "collapsedHelperText": "Erfahren Sie mehr über die Darstellung falsch positiver/ negativer Ergebnisse in Ihrem Dataset.",
      "helperText": "Erstellen Sie Datenset-Kohorten, um Statistiken nach Filtern wie den vorhergesagten Ergebnissen, Dataset-Attribute und Fehlergruppen zu analysieren. Verwenden Sie die X-Achse und die Farbauswahl, um Ihr Dataset weiter in mehr Dimensionen zu unterschneiden.",
      "colorValue": "Farbwert",
      "individualDatapoints": "Einzelne Datenpunkte",
      "aggregatePlots": "Aggregierte Plots",
      "chartType": "Diagrammtyp",
      "missingParameters": "Auf dieser Registerkarte muss ein Auswertungsdataset angegeben werden.",
      "noColor": "Keine"
    },
    "DependencePlot": {
      "featureImportanceOf": "Attributrelevanz von",
      "placeholder": "Klicken Sie im obigen Balkendiagramm auf ein Feature, um den zugehörigen Abhängigkeitsplot anzuzeigen."
    },
    "WhatIfTab": {
      "helperText": "Wählen Sie einen einzelnen Datenpunkt aus, indem Sie im Punktdiagramm auf einen Datenpunkt klicken, um die Werte für die lokale Attributrelevanz unten und die Attributwerte im Bereich auf der rechten Seite anzeigen.",
      "panelPlaceholder": "Für Vorhersagen für neue Datenpunkte ist ein Modell erforderlich.",
      "cohortPickerLabel": "Wählen Sie eine Dataset-Kohorte zur Untersuchung aus",
      "scatterLegendText": "Aktivieren und deaktivieren Sie die Datenpunkte im Plot, indem Sie auf die Legendenelemente klicken.",
      "realPoint": "Reale Datenpunkte",
      "noneSelectedYet": "Noch keine ausgewählt",
      "dataPointInfo": "Datenpunktinformationen",
      "whatIfDatapoints": "Was-wäre-wenn-Datenpunkte",
      "noneCreatedYet": "Noch keine erstellt",
      "showLabel": "Anzeigen:",
      "localFeatureImportanceForPoint": "Wichtigkeit der lokalen Funktion ausgewählter Datenpunkte",
      "featureImportancePlot": "Attributrelevanzplot",
      "icePlot": "ICE-Plot (Individual Conditional Expectation)",
      "featureImportanceLackingParameters": "Geben Sie Werte für die lokale Attributrelevanz an, um festzustellen, wie sich jedes Attribut auf die einzelnen Vorhersagen auswirkt.",
      "featureImportanceGetStartedText": "Markieren eines Punkts, um dessen lokale Wichtigkeit zu sehen",
      "iceLackingParameters": "Für ICE-Plots ist ein operationalisiertes Modell erforderlich, um Vorhersagen für hypothetische Datenpunkte zu treffen.",
      "IceGetStartedText": "Wählen Sie einen Punkt aus, oder erstellen Sie einen Was-wäre-wenn-Punkt, um ICE-Plots anzuzeigen.",
      "whatIfDatapoint": "Was-wäre-wenn-Datenpunkt",
      "whatIfHelpText": "Wählen Sie einen Punkt im Plot aus, oder geben Sie einen bekannten Datenpunktindex manuell ein, um eine Störung hervorzurufen und ihn als neuen Was-wäre-wenn-Punkt zu speichern.",
      "notAvailable": "„Was-wäre-wenn“ wird in Studio derzeit nicht unterstützt. Führen Sie dieses Widget in einem Jupyter Notebook aus, um \"Was-wäre-wenn\" zu aktivieren.",
      "indexLabel": "Datenindex",
      "rowLabel": "Zeile {0}",
      "whatIfNameLabel": "Name des Was-wäre-wenn-Datenpunkts",
      "featureValues": "Attributwerte",
      "predictedClass": "Vorhergesagte Klasse: ",
      "predictedValue": "Vorhergesagter Wert: ",
      "probability": "Wahrscheinlichkeit: ",
      "trueClass": "TRUE-Klasse: ",
      "trueValue": "TRUE-Wert: ",
      "trueValue.comment": "Präfix der tatsächlichen Beschriftung für Regression",
      "newPredictedClass": "Neue vorhergesagte Klasse: ",
      "newPredictedValue": "Neuer vorhergesagter Wert: ",
      "newProbability": "Neue Wahrscheinlichkeit: ",
      "saveAsNewPoint": "Als neuen Punkt speichern",
      "saveChanges": "Änderungen speichern",
      "loading": "Wird geladen...",
      "classLabel": "Klasse: {0}",
      "minLabel": "Min.",
      "maxLabel": "Max.",
      "stepsLabel": "Steps",
      "disclaimer": "Haftungsausschluss: Diese Erläuterungen basieren auf zahlreichen Näherungswerten und stellen nicht die \"Ursache\" von Vorhersagen dar. Ohne absolute mathematische Belastbarkeit der kausalen Rückschlüsse raten wir Benutzern davon ab, basierend auf diesem Tool Entscheidungen in der Praxis zu treffen.",
      "missingParameters": "Auf dieser Registerkarte muss ein Auswertungsdataset angegeben werden.",
      "selectionLimit": "Maximal 3 ausgewählte Punkte",
      "classPickerLabel": "Class",
      "tooltipTitleMany": "Wichtigste {0} vorhergesagte Klassen",
      "whatIfTooltipTitle": "Klassen mit Was-wäre-wenn-Vorhersage",
      "tooltipTitleFew": "Vorhergesagte Klassen",
      "probabilityLabel": "Wahrsch",
      "deltaLabel": "Delta",
      "nonNumericValue": "Der Wert muss numerisch sein",
      "icePlotHelperText": "ICE-Plots zeigen, wie sich die Vorhersagewerte des ausgewählten Datenpunkts entlang eines Bereichs von Attributwerten zwischen einem Mindest- und einem Höchstwert ändern."
    },
    "CohortEditor": {
      "selectFilter": "Filter auswählen",
      "TreatAsCategorical": "Als kategorisch behandeln",
      "addFilter": "Filter hinzufügen",
      "addedFilters": "Freigegebene Filter",
      "noAddedFilters": "Noch keine Filter hinzugefügt.",
      "defaultFilterState": "Wählen Sie einen Filter aus, um Ihrer Datasetkohorte Parameter hinzuzufügen.",
      "cohortNameLabel": "Name der Datasetkohorte",
      "cohortNamePlaceholder": "Benennen Sie Ihre Kohorte",
      "save": "Speichern",
      "delete": "Löschen",
      "cancel": "Abbrechen",
      "cohortNameError": "Kohortenname fehlt",
      "placeholderName": "Kohorte {0}",
      "cancelTitle": "Kohorte abbrechen",
      "cancelNewCohort": "Möchten Sie das Erstellen einer neuen Kohorte abbrechen und zurückkehren?",
      "cancelExistingCohort": "Möchten Sie die Bearbeitung einer Kohorte abbrechen und zurückkehren?",
      "cancelYes": "Ja",
      "cancelNo": "Nein"
    },
    "AxisConfigDialog": {
      "select": "Auswählen",
      "ditherLabel": "Dithern durchführen",
      "selectFilter": "Auswählen Ihres Achsenwerts",
      "selectFeature": "Attribut auswählen",
      "binLabel": "Quantisierung auf Daten anwenden",
      "TreatAsCategorical": "Als kategorisch behandeln",
      "numOfBins": "Datengruppenanzahl",
      "groupByCohort": "Nach Kohorte gruppieren",
      "selectClass": "Klasse auswählen",
      "countHelperText": "Ein Histogramm zur Anzahl der Punkte"
    },
    "ValidationErrors": {
      "predictedProbability": "Wahrscheinlichkeitsvorhersage",
      "predictedY": "Vorhersage für Y",
      "evalData": "Auswertungs-Dataset",
      "globalFeatureImportance": "Globale Attributrelevanz",
      "localFeatureImportance": "Lokale Attributrelevanz",
      "inconsistentDimensions": "Inkonsistente Dimensionen. {0} weist die Dimensionen \"{1}\" auf, erwartet: {2}.",
      "notNonEmpty": "Die Eingabe {0} ist kein nicht leeres Array.",
      "varyingLength": "Inkonsistente Dimensionen. {0} weist Elemente unterschiedlicher Länge auf.",
      "notArray": "{0} ist kein Array. Es wird ein Array mit der Dimension \"{1}\" erwartet.",
      "errorHeader": "Einige Eingabeparameter waren inkonsistent und werden nicht verwendet: ",
      "datasizeWarning": "Das Auswertungsdataset ist zu groß, um in einigen Diagrammen effektiv angezeigt zu werden. Fügen Sie Filter hinzu, um die Größe der Kohorte zu verringern. ",
      "datasizeError": "Die ausgewählte Kohorte ist zu groß. Fügen Sie Filter hinzu, um die Größe der Kohorte zu verringern.",
      "addFilters": "Filter hinzufügen"
    },
    "FilterOperations": {
      "equals": " = {0}",
      "lessThan": " < {0}",
      "greaterThan": " > {0}",
      "lessThanEquals": " <= {0}",
      "greaterThanEquals": " >= {0}",
      "includes": " einschließlich {0} ",
      "excludes": " ausgeschlossen {0}",
      "inTheRangeOf": "[ {0} ]",
      "overflowFilterArgs": "{0} und {1} weitere"
    },
    "Statistics": {
      "mse": "Mittlere quadratische Abweichung: {0}",
      "rSquared": "Bestimmtheitsmaß: {0}",
      "meanPrediction": "Mittlere Vorhersage: {0}",
      "accuracy": "Genauigkeit: {0}",
      "precision": "Genauigkeit: {0}",
      "recall": "Abruf: {0}",
      "fpr": "FPR: {0}",
      "fnr": "FNR: {0}"
    },
    "GlobalOnlyChart": {
      "helperText": "Untersuchen Sie die wichtigsten 1000 Attribute, die sich auf Ihre Modellvorhersagen insgesamt auswirken. Verwenden Sie den Schieberegler, um Attributrelevanzen absteigend anzuzeigen."
    },
    "ExplanationSummary": {
      "whatDoExplanationsMean": "Was bedeuten diese Erklärungen?",
      "clickHere": "Weitere Informationen",
      "shapTitle": "Shapley-Werte",
      "shapDescription": "Dieses Erklärmodul verwendet SHAP, einen spieletheoretischen Ansatz zur Erklärung von Modellen, bei dem die Relevanz von Attributsätzen gemessen wird, indem die betreffenden Features durch Marginalisierung vor dem Modell \"versteckt\" werden. Klicken Sie auf den Link unten, um mehr zu erfahren.",
      "limeTitle": "LIME (Local Interpretable Model-Agnostic Explanations)",
      "limeDescription": "Dieses Erklärmodul verwendet LIME, um eine lineare Näherung des Modells bereitzustellen. Gehen Sie wie folgt vor, um eine Erklärung zu erhalten: Fügen Sie Störungen in die Instanz ein, rufen Sie Modellvorhersagen ab, und verwenden Sie diese Vorhersagen als Beschriftungen, um ein lineares Modell geringer Datendichte zu trainieren, das lokal zuverlässig ist. Die Gewichtungen dieses linearen Modells werden als Attributrelevanz verwendet. Klicken Sie auf den Link unten, um weitere Informationen zu erhalten.",
      "mimicTitle": "Nachahmung (globales Ersatzmodell zur Erklärung)",
      "mimicDescription": "Dieses Erklärmodul basiert auf der Idee, globale Ersatzmodelle zur Nachahmung von Blackbox-Modellen zu trainieren. Ein globales Ersatzmodell ist ein intrinsisch interpretierbares Modell, das so trainiert wird, dass es sich so genau wie möglich an die Vorhersagen eines Black Box-Modells annähert. Die Werte der Attributrelevanz sind modellbasierte Attributrelevanzwerte des zugrunde liegenden Ersatzmodells (LightGBM, lineare Regression, stochastischer Gradientenabstieg oder Entscheidungsstruktur).",
      "pfiTitle": "Permutation Feature Importance (PFI)",
      "pfiDescription": "Dieses Erklärmodul ordnet die Daten für den gesamten Datensatz – jeweils ein Feature nach dem anderen – nach dem Zufallsprinzip an und berechnet, wie sich die relevante Leistungsmetrik ändert (standardmäßige Leistungsmetriken: F1 für binäre Klassifikation, F1-Bewertung mit Mikrodurchschnitt für Mehrklassenklassifikation und mittlerer absoluter Fehler für Regression). Je größer die Änderung, desto relevanter ist das Attribut. Dieses Erklärmodul kann nur das Gesamtverhalten des zugrunde liegenden Modells erklären, nicht jedoch einzelne Vorhersagen. Der Wert der Attributrelevanz repräsentiert das Delta für die Modellleistung, indem dieses bestimmte Attribut gestört wird."
    }
  },
  "CausalAnalysis": {
    "MainMenu": {
      "header": "causal analysis",
      "aggregate": "Aggregate causal effects",
      "individual": "Individual causal effects",
      "treatment": "Treatment policy",
      "title": "Direct causal effect of each feature with 90% confidence interval",
      "why": "Why must causal insights assume unconfoundedness?",
      "learnMore": "Learn more"
    },
    "AggregateView": {
      "description": "Causal analysis answers 'what if' questions about how real world outcomes would have changed if someone had behaved differently, such as pursuing a different pricing strategy for a product or an alternative treatment for a patient. Unlike model predictions that identify important correlation patterns, these tools help you identify the most important causal features that directly affect your outcome of interest. These models identify the causal effect of one feature, holding other confounding features constant. For a good performance, make sure to include a wide set of features that may correlate with the outcome as confounders.",
      "directAggregate": "Direct aggregate causal effect of each treatment with 95% confidence interval",
      "unconfounding": "What are unconfounding variables?",
      "confoundingFeature": "A confounding feature is correlated with both the causal driver and the outcome of interest. The counfounder creates an extra correlation path from the causal driver to the outcome on top of the direct causal effect. Unless confounding features are measured and included in the model, these extra correlations can bias estimates of the causal effect. The bias can be positive or negative, depending on the directions of correlations between omitted confounders, causal drivers, and outcomes.",
      "lasso": "A lasso was fit to predict y from X[-i], and a lasso was fit to predict X[i] from X[-i]. The causal effect can be viewed as the correlation of the residuals/unexplained variations of the two prediction tasks. Learn more about Double Machine Learning here",
      "continuous": "Continuouts treatment variables: ",
      "continuousDescription": "On average in this sample, increasing this feature by 1 unit will cause the outcome to increase by X units",
      "binary": "Binary treatment variables: ",
      "binaryDescription": "On average in this sample, turing on this feature will cause the outcome to increase by X units"
    },
    "IndividualView": {
      "index": "Datapoint index",
      "description": "Individual causal effects can inform targeted or personalized interventions, such as a targeted promition to customers or an individualized treatment plan. How will an individual with a particular set of features respond to a change in a causal driver? These plots show the marginal change in an outcome when each causal driver is changed. The causal what-if tool calculates counterfactual real world outcomes for a particular individual if you changed their causal drivers. For this tool, you need to specify the current outcome and current treatment option for an observation, then specify the counterfactual treatment you would like to explore.",
      "directIndividual": "Direct individual causal effect of each treatment with 95% confidence interval",
      "missingParameters": "This tab requires an evaluation dataset be supplied.",
      "dataRequired": "This tab requires a datapoint be selected.",
      "datapointIndex": "Datapoint index",
      "selectTreatment": "Select treatment",
      "currentTreatment": "Current treatment value",
      "setNewTreatment": "Set new treatment value"
    }
  },
  "ErrorAnalysis": {
    "defaultClassNames": "Klasse {0}",
    "defaultFeatureNames": "Attribut {0}",
    "cells": "Zellen",
    "cellsInfo": "Die Anzahl der im Matrixfilter ausgewählten Zellen. Wenn keine Zellen markiert sind, werden ein - (Gedankenstrich) und die globalen Informationen zur Kohorte so angezeigt, als ob alle Zellen markiert wären.",
    "cellsTitle": "Zusätzliche Informationen über Zellen",
    "cohortInfo": "Kohorteninformationen",
    "correctPrediction": "Richtige Vorhersagen",
    "incorrectPrediction": "Falsche Vorhersagen",
    "whatIfDatapoints": "Was-wäre-wenn-Datenpunkte",
    "allSelected": "Alle ausgewählten",
    "correctTotal": "Richtig/ Gesamt",
    "dataExploration": "Datasetuntersuchung",
    "instanceView": "Instanzansicht",
    "dataExplorerView": "Daten-Explorer",
    "errorCoverage": "Fehlerrate",
    "errorCoverageInfo": "Die Fehlerquote zeigt den Prozentsatz der Fehler an, die in der Auswahl aller im Dataset auftretenden Fehler auftreten.",
    "errorCoverageTitle": "Weitere Informationen zur Fehlerquote",
    "errorRate": "Fehlerquote",
    "errorRateInfo": "Die Fehlerrate stellt den Prozentsatz der Instanzen im Knoten dar, bei denen das System fehlgeschlagen ist.",
    "errorRateTitle": "Weitere Informationen zur Fehlerquote",
    "globalExplanationView": "Globale Erklärung",
    "localExplanationView": "Lokale Erklärung",
    "noFeature": "Kein Attribut",
    "globalImportance": "Globale Relevanz",
    "incorrectTotal": "Falsch/ Gesamt",
    "treeMapDescription": "Wenn Sie die Strukturkarte erneut trainieren möchten, wählen Sie die folgenden Attribute aus und speichern Sie sie. Die Wichtigkeit von Features wurde unter Verwendung gemeinsamer Informationen mit dem Fehler auf den tatsächlichen Beschriftungen berechnet.  Verwenden Sie sie als Richtlinie zum Trainieren der Strukturkarte.",
    "Cohort": {
      "cohort": "Kohorte",
      "defaultLabel": "Alle Daten"
    },
    "CohortInfo": {
      "cohortInformation": "Kohorteninformationen:",
      "saveCohort": "Als neue Kohorte speichern"
    },
    "EditCohort": {
      "subText": "Mehr über die ausgewählte Kohorte erfahren. Den Kohortennamen bearbeiten. Diese Kohorte löschen.",
      "cohortName": "Kohortenname"
    },
    "FeatureList": {
      "importances": "Wichtigkeiten",
      "features": "Attribute"
    },
    "InspectionView": {
      "emptyError": "Wählen Sie Datenpunkte in den Kategorien „Falsch“ und „Richtig“ aus, indem Sie auf die Kontrollkästchen klicken.",
      "selectedDatapoints": "Ausgewählte Datenpunkte"
    },
    "InstanceView": {
      "selection": "{0} ausgewählt",
      "inspect": "Überprüfen"
    },
    "MainMenu": {
      "treeMap": "Baumkarte",
      "heatMap": "Wärmebild",
      "errorAnalysisLabel": "Fehleranalyse",
      "errorExplorerLabel": "Fehler-Explorer:",
      "errorExplorer": "Fehler-Explorer",
      "fullscreen": "Vollbild",
      "whatIf": "Was-wäre-wenn",
      "featureList": "Liste der Attribute",
      "shiftCohort": "Kohorte verschieben",
      "saveCohort": "Kohorte speichern",
      "cohortList": "Kohortenliste",
      "cohortInfo": "Kohorteninformationen",
      "explanation": "Erläuterung",
      "cohortSettings": "Kohorteneinstellungen"
    },
    "MapShift": {
      "subText": "Möchten Sie Ihre Suche mit einer anderen Karte neu starten? Speichern Sie sie als neue Kohorte. Andernfalls gehen die ausgewählten Filter verloren.",
      "title": "Kartneverschiebung",
      "close": "Schließen",
      "move": "Verschieben",
      "saveAs": "Als neue Kohorte speichern",
      "shift": "Verschieben",
      "cancel": "Abbrechen"
    },
    "MatrixArea": {
      "emptyText": "Wählen Sie zwei Attribute aus den oberen Dropdown-Listen aus. Sie können Ihre Daten entlang zweier Dimensionen gruppieren und filtern.",
      "selectAll": "Alles auswählen",
      "clearAll": "Alle löschen"
    },
    "MatrixLegend": {
      "heatMapDescription": "Mit der Rasterkarte können Sie sich auf bestimmte Filter konzentrieren und Fehlerraten kombinieren. Starten Sie mit dem Vergleichen zweier Dataset-Attribute."
    },
    "Navigation": {
      "errorExplorer": "Fehler-Explorer",
      "dataExplorer": "Daten-Explorer",
      "globalExplanation": "Globale Erklärung",
      "localExplanation": "Lokale Erklärung",
      "localExplanationInspection": "Lokale Erklärung (Prüfung)"
    },
    "SaveCohort": {
      "subText": "Speichern der aktuellen Kohorte in der Kohortenliste. Sie können die gespeicherte Kohorte über die Kohortenliste erneut anzeigen.",
      "save": "Speichern",
      "saveTitle": "Als neue Kohorte speichern",
      "cancel": "Abbrechen",
      "close": "Schließen",
      "move": "Verschieben",
      "cohortName": "Kohortenname"
    },
    "TreeView": {
      "treeDescription": "Bei der Strukturvisualisierung werden die gemeinsamen Informationen zwischen den einzelnen Features und der Fehler verwendet, um Fehlerinstanzen von Erfolgsinstanzen in den Daten am besten zu trennen.",
      "treeDescriptionExpanded": "Dies vereinfacht das Erkennen und Hervorheben von häufigen Fehlermustern. Um wesentliche Fehlermuster zu finden, suchen Sie nach Knoten mit deutlicher Rotfärbung (d. h. hohe Fehlerrate) und erhöhter Fülllinie (d. h. hohe Fehlerabdeckung). Um die Liste der im Baum verwendeten Merkmale zu bearbeiten, gehen Sie zum Bedienfeld \"Liste der Attribute\"."
    },
    "WhatIfPanel": {
      "whatIfHeader": "Was-wäre-wenn"
    }
  },
  "Fairness": {
    "loremIpsum": "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.",
    "defaultClassNames": "Klasse {0}",
    "defaultFeatureNames": "Sensibles Attribut {0}",
    "defaultSingleFeatureName": "Sensibles Attribut",
    "defaultCustomMetricName": "Benutzerdefinierte Metrik {0}",
    "performanceTab": "Fairness bei der Leistung",
    "opportunityTab": "Fairness bei Chancen",
    "modelComparisonTab": "Modellvergleich",
    "tableTab": "Detailansicht",
    "dataSpecifications": "Datenstatistik",
    "attributes": "Attribute",
    "singleAttributeCount": "1 sensibles Attribut",
    "attributesCount": "{0} sensible Attribute",
    "instanceCount": "{0} Instanzen",
    "close": "Schließen",
    "done": "Fertig",
    "calculating": "Wird berechnet...",
    "performanceMetricLegacy": "Leistungsmetrik",
    "sensitiveFeatures": "01 sensible Attribute",
    "performanceMetric": "02 Leistungsmetriken",
    "fairnessMetric": "03 Fairness-Metriken",
    "errorOnInputs": "Fehler bei der Eingabe. Sensible Attribute müssen zurzeit kategorische Werte sein. Ordnen Sie den Datengruppenkategorien Werte zu, und versuchen Sie es noch mal.",
    "Performance": {
      "header": "Wie möchten Sie die Leistung messen?",
      "modelMakes": "Ihrem Modell",
      "modelsMake": "Ihren Modellen",
      "body": "Ihre Daten enthalten {0} Beschriftungen, und Vorhersagen werden von {2} zur {1} erstellt. Basierend auf diesen Informationen empfehlen wir die folgenden Metriken. Wählen Sie eine Metrik aus der Liste aus.",
      "binaryClassifier": "binären Klassifizierung",
      "probabilisticRegressor": "Probit-Regression",
      "regressor": "Regression",
      "binary": "binäre",
      "continuous": "fortlaufende"
    },
    "Fairness": {
      "pickerHeader": "Wie möchten Sie die Fairness messen?",
      "header": "Fairness gemessen in Bezug auf die Abweichung",
      "bodyLegacy": "Fairness-Metriken quantifizieren die Variation des Modellverhaltens für die ausgewählten Attribute. Es gibt zwei Arten von Fairness-Metriken: Weitere Informationen folgen...",
      "body": "Bewertungsmetriken, die eine Variation des Verhaltens Ihres Modells über ausgewählte Attribute hinweg darstellen. Es gibt verschiedene Arten von Metriken, die auf einer Vielzahl von Leistungsmetriken basieren. Sie erfassen entweder die Differenz oder das Verhältnis zwischen den Extremwerten in allen Gruppen oder einfach den schlechtesten Wert einer Gruppe."
    },
    "Header": {
      "title": "Fairness",
      "documentation": "Dokumentation"
    },
    "Footer": {
      "back": "Zurück",
      "next": "Weiter"
    },
    "Intro": {
      "welcome": "Willkommen beim",
      "fairnessDashboard": "Fairness-Dashboard",
      "introBody": "Mit dem Fairness-Dashboard können Sie Kompromisse zwischen Leistung und Fairness Ihrer Modelle bewerten.",
      "explanatoryStep": "Um die Bewertung einzurichten, müssen Sie ein sensibles Attribut, eine Leistungsmetrik und eine Fairness-Metrik angeben.",
      "getStarted": "Erste Schritte",
      "features": "Sensible Attribute",
      "featuresInfo": "Anhand sensibler Attribute werden Ihre Daten in Gruppen unterteilt. Die Fairness Ihres Modells in diesen Gruppen wird mithilfe von Fairness-Metriken gemessen. Diese drücken in Zahlen aus, inwieweit das Verhalten Ihres Modells in diesen Gruppen variiert.",
      "performance": "Leistungsmetrik",
      "performanceInfo": "Leistungsmetriken werden verwendet, um die Gesamtqualität Ihres Modells sowie die Qualität Ihres Modells in den einzelnen Gruppen auszuwerten. Der Unterschied zwischen den Extremwerten der Leistungsmetrik in den Gruppen wird als Leistungsabweichung gemeldet.",
      "fairness": "Fairness-Metriken",
      "fairnessInfo": "Fairness-Metriken werden verwendet, um die Gesamtqualität Ihres Modells sowie die Qualität Ihres Modells in den einzelnen Gruppen auszuwerten. Fairness-Metriken können die Differenz oder das Verhältnis zwischen den Extremwerten einer Leistungskennzahl oder einfach den schlechtesten Wert einer Gruppe darstellen."
    },
    "ModelComparison": {
      "title": "Modellvergleich",
      "howToRead": "Lesen dieses Diagramms",
      "lower": "ein geringerer Wert",
      "higher": "ein höherer Wert",
      "howToReadText": "Dieses Diagramm stellt jedes der {0} Modelle als auswählbaren Punkt dar. Die x-Achse stellt \"{1}\" dar, wobei {2} besser ist. Die y-Achse stellt die Abweichung dar, wobei ein geringerer Wert besser ist.",
      "insightsLegacy": "Erkenntnisse",
      "insights": "Wichtigste Erkenntnisse",
      "downloadReport": "Bericht herunterladen",
      "disparity": "Die Abweichung",
      "rangesFrom": " im Bereich von ",
      "to": " zu ",
      "period": ". ",
      "introModalText": "Jedes Modell ist ein auswählbarer Punkt. Klicken oder tippen Sie auf ein Modell, um dessen vollständige Bewertung zu finden.",
      "helpModalText1": "Die X-Achse stellt die Leistung dar, wobei {0} besser ist.",
      "helpModalText2": "Die Y-Achse stellt Werte für die Fairness-Metrik dar, wobei {0} besser ist.",
      "insightsText2": "{0} steht im Bereich von {1} bis {2}. {3} steht im Bereich von {4} bis {5}.",
      "insightsText3": "Das Modell mit der besten Leistung erzielt {0} von {1} und {2} von {3}.",
      "insightsText4": "Das Modell mit dem besten Wert für die Fairness-Metrik erzielt {0} von {1} und {2} von {3}.",
      "insightsText3v1FairnessMetric": "eine Abweichung",
      "disparityInOutcomes": "Abweichung in Vorhersagen",
      "disparityInPerformance": "Abweichung in {0}",
      "howToMeasureDisparity": "Wie soll die Abweichung gemessen werden?"
    },
    "Report": {
      "modelName": "Modell {0}",
      "title": "Leistungsabweichung",
      "globalPerformanceText": "Ist der Gesamtwert von {0}",
      "performanceDisparityText": "Ist die Abweichung in {0}",
      "editConfiguration": "Konfiguration bearbeiten",
      "backToComparisonsLegacy": "Ansicht mit mehreren Modellen",
      "backToComparisons": "Zurück zu allen Modellen",
      "assessmentResults": "Bewertungsergebnisse für",
      "performanceChartHeaderBinaryClassification": "Falsch positive und falsch negative Raten",
      "performanceChartHeaderProbability": "Richtig und falsch negative Vorhersage",
      "performanceChartHeaderRegression": "Verteilung der Fehler",
      "outcomesTitle": "Abweichung in Vorhersagen",
      "expandSensitiveAttributes": "Aufklappen von vertraulichen Attributen",
      "collapseSensitiveAttributes": "Zuklappen von vertraulichen Attributen",
      "minTag": "Min.",
      "maxTag": "Max.",
      "groupLabel": "Untergruppe",
      "overallLabel": "Gesamtintegrität",
      "underestimationError": "Falsch negative Vorhersage",
      "underpredictionExplanation": "(vorhergesagt = 0, richtig = 1)",
      "overpredictionExplanation": "(vorhergesagt = 1, richtig = 0)",
      "overestimationError": "Falsch positive Vorhersage",
      "falseNegativeRate": "Quote der falsch negativen Ergebnisse",
      "falsePositiveRate": "Quote der falsch positiven Ergebnisse",
      "classificationOutcomesHowToRead": "Das Balkendiagramm zeigt die Auswahlrate der einzelnen Gruppen, d. h. den Anteil der als 1 klassifizierten Punkte.",
      "regressionOutcomesHowToRead": "Boxplots zeigen die Verteilung der Vorhersagen in den einzelnen Gruppen. Einzelne Datenpunkte werden darübergelegt.",
      "classificationPerformanceHowToReadV2": "Das Balkendiagramm zeigt die falsch negativen und falsch positiven Ergebnisraten in jeder Gruppe an.",
      "classificationPerformanceHowToRead1": "Das Balkendiagramm zeigt die Verteilung von Fehlern in den einzelnen Gruppen.",
      "classificationPerformanceHowToRead2": "Fehler werden in falsch positive Vorhersagen (Vorhersage von 1 bei einer Beschriftung von 0) und falsch negative Vorhersagen (Vorhersage von 0 bei einer Beschriftung von 1) unterteilt.",
      "classificationPerformanceHowToRead3": "Die gemeldeten Raten werden durch Teilen der Fehleranzahl durch die Gesamtgröße der Gruppe ermittelt.",
      "probabilityPerformanceHowToRead1": "Das Balkendiagramm zeigt die mittlere absolute Abweichung in den einzelnen Gruppen, aufgeteilt in falsch positive und falsch negative Vorhersagen.",
      "probabilityPerformanceHowToRead2": "In jedem Beispiel wird die Differenz zwischen der Vorhersage und der Beschriftung gemessen. Wenn diese positiv ist, wird dies als falsch positive Vorhersage bezeichnet. Ist sie negativ, handelt es sich um eine falsch negative Vorhersage.",
      "probabilityPerformanceHowToRead3": "Wir melden die Summe der Fehler durch falsch positive Vorhersagen und die Summe der Fehler durch falsch negative Vorhersagen, geteilt durch die Gesamtgröße der Gruppe.",
      "regressionPerformanceHowToRead": "Ein Fehler ist der Unterschied zwischen der Vorhersage und der Beschriftung. Boxplots zeigen die Verteilung von Fehlern in den einzelnen Gruppen. Einzelne Datenpunkte werden darübergelegt.",
      "distributionOfPredictions": "Verteilung der Vorhersagen",
      "distributionOfErrors": "Fehlerverteilung",
      "tooltipPrediction": "Vorhersage: {0}",
      "tooltipError": "Fehler: {0}",
      "chartChoiceDropdownHeader": "Diagramme"
    },
    "Feature": {
      "header": "Anhand welcher Features möchten Sie die Fairness Ihres Modells auswerten?",
      "body": "Fairness wird hinsichtlich der Abweichungen im Verhalten Ihres Modells ausgewertet. Wir teilen Ihre Daten entsprechend den Werten der einzelnen ausgewählten Features auf und bewerten, wie sich die Leistungsmetrik und die Vorhersagen Ihres Modells in den einzelnen Teilen unterscheiden.",
      "learnMore": "Weitere Informationen",
      "summaryCategoricalCount": "Dieses Attribut verfügt über {0} eindeutige Werte",
      "summaryNumericCount": "Der Bereich dieses numerischen Features liegt zwischen {0} und {1} und ist in {2} Datengruppen unterteilt.",
      "showCategories": "Alle anzeigen",
      "hideCategories": "Reduzieren",
      "categoriesOverflow": "   ud {0} weitere Kategorien",
      "editBinning": "Gruppen bearbeiten",
      "subgroups": "Untergruppen"
    },
    "Metrics": {
      "accuracyScore": "Genauigkeit",
      "precisionScore": "Genauigkeit",
      "recallScore": "Wiedererkennung",
      "zeroOneLoss": "Null-Eins-Verlust",
      "specificityScore": "Spezifitätsscore",
      "missRate": "Fehlerrate",
      "falloutRate": "Ausfallrate",
      "maxError": "Maximaler Fehler",
      "meanAbsoluteError": "Mittlere absolute Abweichung",
      "meanSquaredError": " Mittlere quadratische Abweichung",
      "meanSquaredLogError": "Mittlerer quadratischer logarithmischer Fehler",
      "medianAbsoluteError": "Mittlere absolute Abweichung vom Median",
      "average": "Durchschnittliche Vorhersage",
      "selectionRate": "Auswahlrate",
      "overprediction": "Falsch positive Vorhersage",
      "underprediction": "Falsch negative Vorhersage",
      "falsePositiveRate": "Quote der falsch positiven Ergebnisse",
      "falseNegativeRate": "Quote der falsch negativen Ergebnisse",
      "r2_score": "R-quadratischer Score",
      "rms_error": "Wurzel der mittleren Fehlerquadratsumme (RMSE)",
      "auc": "Fläche unter der ROC-Kurve",
      "balancedRootMeanSquaredError": "Wurzel der ausgeglichenen Fehlerquadratsumme (RMSE), normalisiert",
      "balancedAccuracy": "Ausgewogene Genauigkeit",
      "f1Score": "F1-Bewertung",
      "logLoss": "Protokollverlust",
      "accuracyDescription": "Der Anteil der Datenpunkte, die korrekt klassifiziert werden.",
      "precisionDescription": "Der Anteil der Datenpunkte, die unter den als 1 klassifizierten Datenpunkten korrekt klassifiziert werden.",
      "recallDescription": "Der Anteil der Datenpunkte, die unter denjenigen korrekt klassifiziert werden, deren echte Beschriftung 1 lautet. Alternative Namen: True Positive-Rate, Sensitivität.",
      "rmseDescription": "Quadratwurzel des Durchschnitts von quadratischen Fehlern.",
      "mseDescription": "Der Durchschnitt aus quadratischen Fehlern.",
      "meanAbsoluteErrorDescription": "Der Durchschnitt der absoluten Fehlerwerte. Stabiler bei Ausreißern als MQA.",
      "r2Description": "Der Anteil der Varianz in den Beschriftungen, die vom Modell erklärt werden.",
      "f1ScoreDescription": "F1-Bewertung ist das harmonische Mittel der Genauigkeit und des Abrufs.",
      "aucDescription": "Die Qualität der Vorhersagen, dargestellt als Scores, beim Trennen positiver Beispiele von negativen Beispielen.",
      "balancedRMSEDescription": "Positive und negative Beispiele werden neu gewichtet, sodass sie insgesamt die gleiche Gewichtung aufweisen. Diese Option ist geeignet, wenn die zugrunde liegenden Daten hochgradig unausgewogen sind.",
      "balancedAccuracyDescription": "Positive und negative Beispiele werden neu gewichtet, sodass sie insgesamt die gleiche Gewichtung aufweisen. Diese Option ist geeignet, wenn die zugrunde liegenden Daten hochgradig unausgewogen sind.",
      "falsePositiveRateDescription": "Die Anzahl der falsch klassifizierten Datenpunkte unter denjenigen, deren richtige Bezeichnung 0 ist.",
      "falseNegativeRateDescription": "Die Anzahl der falsch klassifizierten Datenpunkte unter denjenigen, deren richtige Bezeichnung 1 ist.",
      "accuracyScoreDifference": "Unterschied bei der Genauigkeitspunktzahl",
      "accuracyScoreDifferenceDescription": "Die maximale Differenz bei der Genauigkeitsbewertung zwischen zwei Gruppen.",
      "accuracyScoreMin": "Mindestwertung der Genauigkeit",
      "accuracyScoreMinDescription": "Die minimale Genauigkeitsbewertung aller Gruppen.",
      "accuracyScoreRatio": "Verhältnis der Genauigkeitsbewertung",
      "accuracyScoreRatioDescription": "Das minimale Verhältnis bei der Genauigkeitsbewertung zwischen zwei Gruppen.",
      "balancedAccuracyScoreMin": "Mindestpunktzahl für ausgeglichene Genauigkeit",
      "balancedAccuracyScoreMinDescription": "Der Mindestwert für den Gruppenabrufdurchschnitt für jede Klasse (0 und 1).",
      "demographicParityDifference": "Unterschiede bei der demographischen Parität",
      "demographicParityDifferenceDescription": "Die maximale Differenz bei der Auswahlrate, d. h. der Bruch mit der vorhergesagten Beschriftung 1 zwischen zwei Gruppen.",
      "demographicParityRatio": "Verhältnis bei der demographischen Parität",
      "demographicParityRatioDescription": "Das Mindestverhältnis bei der Auswahlrate, d. h. der Bruch mit der vorhergesagten Beschriftung 1 zwischen zwei Gruppen.",
      "equalizedOddsDifference": "Differenz der ausgleichenden Quoten",
      "equalizedOddsDifferenceDescription": "Entweder der maximale Unterschied zwischen den tatsächlich positiven Sätzen zweier Gruppen oder der maximale Unterschied zwischen falsch positiven Sätzen von zwei Gruppen, je nachdem, was größer ist.",
      "equalizedOddsRatio": "Verhältnis der ausgleichenden Quoten",
      "equalizedOddsRatioDescription": "Entweder das minimale Verhältnis zwischen den tatsächlich positiven Sätzen zweier Gruppen oder das minimale Verhältnis zwischen falsch positiven Sätzen von zwei Gruppen, je nachdem, was kleiner ist.",
      "trueNegativeRateDifference": "Quotendifferenz der richtig negativen Ergebnisse",
      "errorRateDifference": "Differenz der Fehlerquote",
      "errorRateDifferenceDescription": "Die maximale Differenz zwischen den Fehlerquoten von zwei Gruppen.",
      "errorRateRatio": "Fehlerratenverhältnis",
      "errorRateRatioDescription": "Das Mindestverhältnis zwischen den Fehlerquoten von zwei Gruppen.",
      "f1ScoreMin": "Minimaöe F1-Bewertung",
      "f1ScoreMinDescription": "Die minimale F1-Bewertung aller Gruppen.",
      "falseNegativeRateDifference": "Quotendifferenz der falsch negativen Ergebnisse",
      "falseNegativeRateDifferenceDescription": "Der maximale Unterschied zwischen falsch negativer Quoten von zwei Gruppen. Manchmal auch als \"Differenz der Fehlerbedingungen\" bezeichnet.",
      "falseNegativeRateRatio": "Quotenverhältnis der falsch negativen Ergebnisse",
      "falseNegativeRateRatioDescription": "Das Mindestverhältnis zwischen falsch negativen Quoten beliebiger Gruppen. Wird manchmal auch als \"Fehlbedingungsqoute\" bezeichnet.",
      "falsePositiveRateDifference": "Quotendifferenz der falsch positiven Ergebnisse",
      "falsePositiveRateDifferenceDescription": "Der maximale Unterschied zwischen richtig negativer Quoten von zwei Gruppen. Manchmal auch als \"Ausfalldifferenz\" bezeichnet.",
      "falsePositiveRateRatio": "Quotenverhältnis der falsch positiven Ergebnisse",
      "falsePositiveRateRatioDescription": "Das Mindestverhältnis zwischen falsch positiven Quoten beliebiger Gruppen. Wird manchmal auch als \"Ausfallqoute\" bezeichnet.",
      "logLossMax": "Maximale Protokollverluste",
      "logLossMaxDescription": "Der maximale logistische Verlust aller Gruppen.",
      "meanAbsoluteErrorMax": "Maximale mittlere absolute Abweichung",
      "meanAbsoluteErrorMaxDescription": "Die maximale mittlere absolute Abweichung aller Gruppen.",
      "meanSquaredErrorMax": "Maximale mittlere quadratische Abweichung",
      "meanSquaredErrorMaxDescription": "Die maximale mittlere quadratische Abweichung aller Gruppen.",
      "precisionScoreMin": "Minimale Genauigkeitsbwertung",
      "precisionScoreMinDescription": "Die minimale Genauigkeitsbewertung aller Gruppen.",
      "r2ScoreMin": "R2-Mindestbewertung",
      "r2ScoreMinDescription": "Die minimale R2-Bewertung aller Gruppen.",
      "recallScoreMin": "Minimale Abrufbewertung",
      "recallScoreMinDescription": "Die minimale Abrufbewertung aller Gruppen.",
      "ROCAUCScoreMin": "Mindestpunktzahl ROC AUC",
      "ROCAUCScoreMinDescription": "Die minimale Area Under the Receiver Operating Characteristic Curve (ROC AUC) aller Gruppen.",
      "trueNegativeRateDifferenceDescription": "Der maximale Unterschied zwischen richtig negativer Quoten von zwei Gruppen. Manchmal auch als \"Unterschied der Genauigkeitsbewertung\" bezeichnet.",
      "trueNegativeRateRatio": "Quotenverhältnis der richtig negativen Ergebnisse",
      "trueNegativeRateRatioDescription": "Das Mindestverhältnis zwischen richtig negativen Quoten beliebiger Gruppen. Wird manchmal auch als \"Quote der Spezifizitätsbewertung\" bezeichnet.",
      "truePositiveRateDifference": "Quotendifferenz der richtig positiven Ergebnisse",
      "truePositiveRateDifferenceDescription": "Die maximale Differenz zwischen richtig positiven Quoten beliebiger Gruppen. Wird manchmal auch als \"Chancengleichheitsdifferenz oder Abrufdifferenz\" bezeichnet.",
      "truePositiveRateRatio": "Quotenverhältnis der richtig positiven Ergebnisse",
      "truePositiveRateRatioDescription": "Das Mindestverhältnis zwischen richtig positiven Quoten beliebiger Gruppen. Wird manchmal auch als \"Chancengleichheitsrate oder Abrufbewertung\" bezeichnet.",
      "Groups": {
        "equalizedOdds": "Ausgleichende Quoten",
        "classificationAccuracyAndErrorRate": "Genauigkeit/ Fehlerquote",
        "regressionError": "Fehler",
        "selectionRate": "Demografische Parität/ Auswahlrate",
        "trueNegativeRate": "Quote der richtig negativen Ergebnisse/ Spezifität",
        "truePositiveRate": "Quote der richtig positiven Ergebnisse/ Abruf/ Sensibilität",
        "falseNegativeRate": "Quote der falsch positiven Ergebnisse/ Fehlbedingungsqoute",
        "falsePositiveRate": "Quote der falsch positiven Ergebnisse/ Ausfälle",
        "precision": "Genauigkeit",
        "overUnderPrediction": "Richtig und falsch negative Vorhersage",
        "auc": "Fläche unter der ROC-Kurve",
        "average": "Durchschnittliche Vorhersage",
        "f1_score": "F1-Bewertung",
        "loss": "Verlust",
        "r2_score": "R-quadratischer Score",
        "custom": "Benutzerdefinierte Metriken"
      }
    },
    "BinDialog": {
      "header": "Datengruppen konfigurieren",
      "makeCategorical": "Als kategorisch behandeln",
      "save": "Speichern",
      "cancel": "Abbrechen",
      "numberOfBins": "Datengruppenanzahl:",
      "categoryHeader": "Datengruppenwerte:"
    },
    "DropdownHeaders": {
      "sensitiveFeature": "Sensibles Attribut",
      "performanceMetric": "Leistungsmetrik",
      "fairnessMetric": "Fairness-Metrik"
    }
  },
  "ModelAssessment": {
    "Navigation": {
      "modelStatistics": "Modellstatistiken"
    },
    "AddingTab": {
      "CalloutTitle": "Komponente hinzufügen",
      "CalloutContent": "Durch das Hinzufügen einiger Komponenten (Fehlerstrukturansicht, Fehlerwärmebild) können Sie die Daten aus der globalen Kohorte abwärts filtern, um sie in den nachstehenden Komponenten entsprechend anzuzeigen.",
      "AddButtonText": "Hinzufügen"
    },
    "CasualAnalysis": {
      "Table": {
        "name": "feature",
        "point": "point",
        "stderr": "stderr",
        "zstat": "zstat",
        "pValue": "p_value",
        "ciLower": "ci_lower",
        "ciUpper": "ci_upper"
      }
    },
    "ComponentNames": {
      "DataExplorer": "Daten-Explorer",
      "GlobalExplanation": "Globale Erklärung",
      "LocalExplanation": "Lokale Erklärung",
      "ErrorAnalysis": "Fehleranalyse",
      "Fairness": "Fairness",
      "ModelStatistics": "Modellstatistiken",
      "CausalAnalysis": "Ursachenanalyse",
      "Counterfactuals": "Alternativen"
    },
    "MainMenu": {
      "DashboardSettings": "Dashboardeinstellungen"
    },
    "DashboardSettings": {
      "Title": "Dashboardlayout",
      "Content": "Diese Liste zeigt das Layout des Dashboards. Jede mit \"Identifizieren\" markierte Komponente kann Daten abwärts filtern, die in den darunter aufgeführten Komponenten angezeigt werden sollen. Sie können Komponenten hinzufügen, per Drag & Drop verschieben, um den Flow neu anzuordnen, oder Komponenten löschen.",
      "DashboardComponents": "Dashboardkomponenten",
      "DataPoints": "Anzahl von Datenpunkten"
    }
  }
}