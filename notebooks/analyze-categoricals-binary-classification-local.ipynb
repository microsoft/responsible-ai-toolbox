{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze categorical binary classification model predictions\n",
    "_**This notebook showcases how to use error analysis to help understand the errors in a binary classification model.**_\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Introduction](#Introduction)\n",
    "1. [Setup](#Setup)\n",
    "1. [Project](#Project)\n",
    "1. [Run model explainer locally at training time](#Explain)\n",
    "    1. Train a binary classification model\n",
    "    1. Explain the model\n",
    "        1. Generate global explanations\n",
    "        1. Generate local explanations\n",
    "1. [Visualize results](#Analyze)\n",
    "1. [Next steps](#Next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Introduction'></a>\n",
    "## 1. Introduction\n",
    "\n",
    "This notebook illustrates how to locally use interpret-community to help interpret binary classification model predictions at training time.  It demonstrates the API calls needed to obtain the global and local interpretations along with an interactive visualization dashboard for discovering patterns in data and explanations.\n",
    "\n",
    "Three tabular data explainers are demonstrated: \n",
    "- TabularExplainer (SHAP)\n",
    "- MimicExplainer (global surrogate)\n",
    "- PFIExplainer.\n",
    "\n",
    "| ![Interpretability Toolkit Architecture](./img/interpretability-architecture.png) |\n",
    "|:--:|\n",
    "| *Interpretability Toolkit Architecture* |\n",
    "\n",
    "<a id='Project'></a>       \n",
    "## 2. Project\n",
    "\n",
    "The goal of this project is to classify breast cancer diagnosis with scikit-learn and locally running the model explainer:\n",
    "\n",
    "1. Train a SVM classification model using Scikit-learn\n",
    "2. Run 'explain_model' globally and locally with full dataset in local mode, which doesn't contact any Azure services.\n",
    "3. Visualize the global and local explanations with the visualization dashboard.\n",
    "\n",
    "<a id='Setup'></a>\n",
    "## 3. Setup\n",
    "\n",
    "If you are using Jupyter notebooks, the extensions should be installed automatically with the package.\n",
    "If you are using Jupyter Labs run the following command:\n",
    "```\n",
    "(myenv) $ jupyter labextension install @jupyter-widgets/jupyterlab-manager\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Explain'></a>\n",
    "## 4. Run model explainer locally at training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Explainers:\n",
    "# 1. SHAP Tabular Explainer\n",
    "#from interpret.ext.blackbox import TabularExplainer\n",
    "from interpret.ext.blackbox import TabularExplainer\n",
    "\n",
    "# OR\n",
    "\n",
    "# 2. Mimic Explainer\n",
    "from interpret.ext.blackbox import MimicExplainer\n",
    "from interpret.ext.glassbox import LinearExplainableModel\n",
    "from interpret.ext.glassbox import LGBMExplainableModel\n",
    "\n",
    "# You can use one of the following four interpretable models as a global surrogate to the black box model\n",
    "#from interpret.ext.glassbox import LGBMExplainableModel\n",
    "#from interpret.ext.glassbox import LinearExplainableModel\n",
    "#from interpret.ext.glassbox import SGDExplainableModel\n",
    "#from interpret.ext.glassbox import DecisionTreeExplainableModel\n",
    "\n",
    "# OR\n",
    "\n",
    "# 3. PFI Explainer\n",
    "#from interpret.ext.blackbox import PFIExplainer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the UCI adult census income dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdirname = 'erroranalysis.12.3.20'\n",
    "try:\n",
    "    from urllib import urlretrieve\n",
    "except ImportError:\n",
    "    from urllib.request import urlretrieve\n",
    "zipfilename = outdirname + '.zip'\n",
    "urlretrieve('https://publictestdatasets.blob.core.windows.net/data/' + zipfilename, zipfilename)\n",
    "with zipfile.ZipFile(zipfilename, 'r') as unzip:\n",
    "    unzip.extractall('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('adult-train.csv')\n",
    "test_data = pd.read_csv('adult-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "test_data_full = test_data\n",
    "test_data, _ = train_test_split(test_data, test_size=0.9, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "def split_label(dataset):\n",
    "    X = dataset.drop(['income'], axis=1)\n",
    "    y = dataset[['income']]\n",
    "    return X, y\n",
    "\n",
    "def clean_data(X, y):\n",
    "    features = X.columns.values.tolist()\n",
    "    classes = y['income'].unique().tolist()\n",
    "    pipe_cfg = {\n",
    "        'num_cols': X.dtypes[X.dtypes == 'int64'].index.values.tolist(),\n",
    "        'cat_cols': X.dtypes[X.dtypes == 'object'].index.values.tolist(),\n",
    "    }\n",
    "    num_pipe = Pipeline([\n",
    "        ('num_imputer', SimpleImputer(strategy='median')),\n",
    "        ('num_scaler', StandardScaler())\n",
    "    ])\n",
    "    cat_pipe = Pipeline([\n",
    "        ('cat_imputer', SimpleImputer(strategy='constant', fill_value='?')),\n",
    "        ('cat_encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "    ])\n",
    "    feat_pipe = ColumnTransformer([\n",
    "        ('num_pipe', num_pipe, pipe_cfg['num_cols']),\n",
    "        ('cat_pipe', cat_pipe, pipe_cfg['cat_cols'])\n",
    "    ])\n",
    "    X = feat_pipe.fit_transform(X)\n",
    "    return X, feat_pipe, features, classes\n",
    "\n",
    "X_train_original, y_train = split_label(train_data)\n",
    "X_train, feat_pipe, features, classes = clean_data(X_train_original, y_train)\n",
    "X_test_original, y_test = split_label(test_data)\n",
    "X_test_original_full, y_test_full = split_label(test_data_full)\n",
    "y_test = y_test['income'].to_numpy()\n",
    "y_test_full = y_test_full['income'].to_numpy()\n",
    "X_test = feat_pipe.transform(X_test_original)\n",
    "features = train_data.columns.values[1:].tolist()\n",
    "classes = y_train['income'].unique().tolist()\n",
    "categorical_features = train_data.dtypes[train_data.dtypes == 'object'].index.values[1:].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a LightGBM classification model, which you want to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LGBMClassifier(n_estimators=1)\n",
    "model = clf.fit(X_train, y_train['income'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain predictions on your local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret_community.common.constants import ShapValuesOutput, ModelTask\n",
    "# 1. Using SHAP TabularExplainer\n",
    "model_task = ModelTask.Classification\n",
    "explainer = MimicExplainer(model, X_train_original, LGBMExplainableModel,\n",
    "                            augment_data=True, max_num_of_augmentations=10,\n",
    "                            features=features, classes=classes, model_task=model_task,\n",
    "                            transformations=feat_pipe)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2. Using MimicExplainer\n",
    "# augment_data is optional and if true, oversamples the initialization examples to improve surrogate model accuracy to fit original model.  Useful for high-dimensional data where the number of rows is less than the number of columns. \n",
    "# max_num_of_augmentations is optional and defines max number of times we can increase the input data size.\n",
    "# LGBMExplainableModel can be replaced with LinearExplainableModel, SGDExplainableModel, or DecisionTreeExplainableModel\n",
    "# explainer = MimicExplainer(model, \n",
    "#                            x_train, \n",
    "#                            LGBMExplainableModel, \n",
    "#                            augment_data=True, \n",
    "#                            max_num_of_augmentations=10, \n",
    "#                            features=breast_cancer_data.feature_names, \n",
    "#                            classes=classes)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 3. Using PFIExplainer\n",
    "\n",
    "# Use the parameter \"metric\" to pass a metric name or function to evaluate the permutation. \n",
    "# Note that if a metric function is provided a higher value must be better.\n",
    "# Otherwise, take the negative of the function or set the parameter \"is_error_metric\" to True.\n",
    "# Default metrics: \n",
    "# F1 Score for binary classification, F1 Score with micro average for multiclass classification and\n",
    "# Mean absolute error for regression\n",
    "\n",
    "# explainer = PFIExplainer(model, \n",
    "#                          features=breast_cancer_data.feature_names, \n",
    "#                          classes=classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate global explanations\n",
    "Explain overall model predictions (global explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passing in test dataset for evaluation examples - note it must be a representative sample of the original data\n",
    "# x_train can be passed as well, but with more examples explanations will take longer although they may be more accurate\n",
    "global_explanation = explainer.explain_global(X_test_original)\n",
    "\n",
    "# Note: if you used the PFIExplainer in the previous step, use the next line of code instead\n",
    "# global_explanation = explainer.explain_global(x_test, true_labels=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorted SHAP values\n",
    "print('ranked global importance values: {}'.format(global_explanation.get_ranked_global_values()))\n",
    "# Corresponding feature names\n",
    "print('ranked global importance names: {}'.format(global_explanation.get_ranked_global_names()))\n",
    "# Feature ranks (based on original order of features)\n",
    "print('global importance rank: {}'.format(global_explanation.global_importance_rank))\n",
    "\n",
    "# Note: Do not run this cell if using PFIExplainer, it does not support per class explanations\n",
    "# Per class feature names\n",
    "print('ranked per class feature names: {}'.format(global_explanation.get_ranked_per_class_names()))\n",
    "# Per class feature importance values\n",
    "print('ranked per class feature values: {}'.format(global_explanation.get_ranked_per_class_values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out a dictionary that holds the sorted feature importance names and values\n",
    "print('global importance rank: {}'.format(global_explanation.get_feature_importance_dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "dashboard_pipeline = Pipeline(steps=[('preprocess', feat_pipe), ('model', model)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Analyze'></a>\n",
    "## 5. Analyze\n",
    "Analyze using Error Analysis Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from raiwidgets import ErrorAnalysisDashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run error analysis on the full dataset with subsampled explanation data on 5k rows\n",
    "# Note in this case we need to provide the true_y_dataset parameter matching the\n",
    "# original full dataset\n",
    "ErrorAnalysisDashboard(global_explanation, dashboard_pipeline, dataset=X_test_original_full,\n",
    "                       true_y=y_test, categorical_features=categorical_features,\n",
    "                       true_y_dataset=y_test_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Next'></a>\n",
    "## 6. Next steps\n",
    "Learn about other use cases of the explain package on a:\n",
    "       \n",
    "1. [Training time: regression problem](./explain-regression-local.ipynb)\n",
    "1. [Training time: multiclass classification problem](./explain-multiclass-classification-local.ipynb)\n",
    "1. Explain models with engineered features:\n",
    "    1. [Simple feature transformations](./simple-feature-transformations-explain-local.ipynb)\n",
    "    1. [Advanced feature transformations](./advanced-feature-transformations-explain-local.ipynb)"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "mesameki"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
